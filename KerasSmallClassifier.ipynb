{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Input, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, LambdaCallback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_data.csv')\n",
    "# Convert labels\n",
    "data.loc[data.CONT == \"NO\",\"CONT\"] = 0\n",
    "data.loc[data.CONT != 0,\"CONT\"] = 1\n",
    "# Subset columns\n",
    "cols = [\"BUN\",\"CA\",\"CL\",\"CO2\",\"CRET\",\"GLU\",\"K\",\"NA.\",\"CONT\"]\n",
    "data = data[cols]\n",
    "# Banish negativity :)\n",
    "data.loc[data.CA < 0,\"CA\"] = 0\n",
    "# Convert to int.  Could save space with binary, but meh...\n",
    "data.CONT = data.CONT.astype(\"int64\")\n",
    "# Drop NAs\n",
    "data = data.dropna()\n",
    "# To numpy, Batman!\n",
    "data = data.as_matrix()\n",
    "# Normalize features\n",
    "num_features = len(cols)-1\n",
    "means = np.zeros(num_features)\n",
    "stds = np.zeros(num_features)\n",
    "for x in range(data.shape[1]-1):\n",
    "    means[x] = data[:,x].mean()\n",
    "    stds[x] = data[:,x].std()\n",
    "    data[:,x] = (data[:,x]-means[x])/stds[x]\n",
    "# Split\n",
    "test_samples, val_samples = [int(.2*len(data))]*2\n",
    "np.random.shuffle(data)\n",
    "test = data[:test_samples,:]\n",
    "val = data[test_samples:test_samples+val_samples,:]\n",
    "train = data[test_samples+val_samples:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildNet(lr=1e-3, dropoutA=.2, dropoutB=.2, dropoutC=.2):\n",
    "    inputLayer = Input(shape = (8,))\n",
    "    D = Dropout(dropoutA)(inputLayer)\n",
    "    D = Dense(64)(D)\n",
    "    D = Activation('relu')(D)\n",
    "    D = Dropout(dropoutB)(D)\n",
    "    D = Dense(32)(D)\n",
    "    D = Activation('relu')(D)\n",
    "    D = Dropout(dropoutC)(D)\n",
    "    pred = Dense(1,activation = 'sigmoid')(D)\n",
    "    model = Model(input = inputLayer, output=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr))\n",
    "    return model\n",
    "\n",
    "def trainAndPredict(model, nb_epoch=100, batch_size=len(train)):\n",
    "    #plotterT = LambdaCallback(on_epoch_end=lambda epoch, logs: plt.plot(epoch, logs['loss']))\n",
    "    #plotterV = LambdaCallback(on_epoch_end=lambda epoch, logs: plt.plot(np.arange(epoch), logs['val_loss']))\n",
    "    stopper = EarlyStopping(patience = 3, verbose = 1)\n",
    "    model.fit(train[:,:8],train[:,-1],validation_data=(val[:,:8],val[:,-1]),\n",
    "              nb_epoch=int(round(nb_epoch)), batch_size=int(round(batch_size)),callbacks=[stopper])\n",
    "    return model.predict(val[:,:8])\n",
    "\n",
    "def evalAUC(y_pred,y_val=val[:,-1]):\n",
    "    return roc_auc_score(y_val,y_pred)\n",
    "\n",
    "def measurable(lr=1e-3, dropoutA=.2, dropoutB=.2, dropoutC=.2, nb_epoch=100, batch_size=len(train)):\n",
    "    model = buildNet(lr,dropoutA,dropoutB,dropoutC)\n",
    "    y_pred = trainAndPredict(model, nb_epoch,batch_size)\n",
    "    return evalAUC(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'lr':(1e-5,.01), 'dropoutA':(.01,.6),'dropoutB':(.01,.6),'dropoutC':(.01,.6)}\n",
    "BO = BayesianOptimization(measurable, params)\n",
    "BO.maximize(init_points=5,n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_params': {'dropoutA': 0.083730742972679156,\n",
       "  'dropoutB': 0.37669203808894514,\n",
       "  'dropoutC': 0.26408076037832368,\n",
       "  'lr': 0.019685168087984706},\n",
       " 'max_val': 0.99911993724769932}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BO.res['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8367 samples, validate on 2789 samples\n",
      "Epoch 1/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.6157 - val_loss: 0.3245\n",
      "Epoch 2/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.3484 - val_loss: 0.2088\n",
      "Epoch 3/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.2350 - val_loss: 0.1613\n",
      "Epoch 4/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.1914 - val_loss: 0.1383\n",
      "Epoch 5/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.1624 - val_loss: 0.1198\n",
      "Epoch 6/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.1533 - val_loss: 0.0993\n",
      "Epoch 7/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.1260 - val_loss: 0.0824\n",
      "Epoch 8/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.1031 - val_loss: 0.0703\n",
      "Epoch 9/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0942 - val_loss: 0.0634\n",
      "Epoch 10/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0820 - val_loss: 0.0598\n",
      "Epoch 11/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0734 - val_loss: 0.0585\n",
      "Epoch 12/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0749 - val_loss: 0.0585\n",
      "Epoch 13/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0674 - val_loss: 0.0588\n",
      "Epoch 14/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0691 - val_loss: 0.0584\n",
      "Epoch 15/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0680 - val_loss: 0.0569\n",
      "Epoch 16/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0603 - val_loss: 0.0517\n",
      "Epoch 17/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0597 - val_loss: 0.0466\n",
      "Epoch 18/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0583 - val_loss: 0.0420\n",
      "Epoch 19/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0498 - val_loss: 0.0391\n",
      "Epoch 20/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0512 - val_loss: 0.0377\n",
      "Epoch 21/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0437 - val_loss: 0.0369\n",
      "Epoch 22/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0478 - val_loss: 0.0363\n",
      "Epoch 23/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0439 - val_loss: 0.0356\n",
      "Epoch 24/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0351 - val_loss: 0.0347\n",
      "Epoch 25/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0397 - val_loss: 0.0334\n",
      "Epoch 26/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0376 - val_loss: 0.0318\n",
      "Epoch 27/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0389 - val_loss: 0.0300\n",
      "Epoch 28/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0330 - val_loss: 0.0281\n",
      "Epoch 29/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 30/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0331 - val_loss: 0.0248\n",
      "Epoch 31/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0312 - val_loss: 0.0237\n",
      "Epoch 32/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0216 - val_loss: 0.0228\n",
      "Epoch 33/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0286 - val_loss: 0.0221\n",
      "Epoch 34/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0338 - val_loss: 0.0215\n",
      "Epoch 35/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0292 - val_loss: 0.0209\n",
      "Epoch 36/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0260 - val_loss: 0.0204\n",
      "Epoch 37/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0290 - val_loss: 0.0199\n",
      "Epoch 38/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0222 - val_loss: 0.0195\n",
      "Epoch 39/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0259 - val_loss: 0.0192\n",
      "Epoch 40/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0255 - val_loss: 0.0189\n",
      "Epoch 41/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0228 - val_loss: 0.0187\n",
      "Epoch 42/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0295 - val_loss: 0.0185\n",
      "Epoch 43/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0211 - val_loss: 0.0183\n",
      "Epoch 44/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0242 - val_loss: 0.0181\n",
      "Epoch 45/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0217 - val_loss: 0.0178\n",
      "Epoch 46/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0221 - val_loss: 0.0174\n",
      "Epoch 47/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0243 - val_loss: 0.0171\n",
      "Epoch 48/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0204 - val_loss: 0.0168\n",
      "Epoch 49/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0238 - val_loss: 0.0165\n",
      "Epoch 50/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0189 - val_loss: 0.0164\n",
      "Epoch 51/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0290 - val_loss: 0.0163\n",
      "Epoch 52/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0240 - val_loss: 0.0163\n",
      "Epoch 53/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0278 - val_loss: 0.0162\n",
      "Epoch 54/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0156 - val_loss: 0.0161\n",
      "Epoch 55/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0215 - val_loss: 0.0159\n",
      "Epoch 56/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0175 - val_loss: 0.0158\n",
      "Epoch 57/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0212 - val_loss: 0.0156\n",
      "Epoch 58/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0225 - val_loss: 0.0155\n",
      "Epoch 59/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0235 - val_loss: 0.0154\n",
      "Epoch 60/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0236 - val_loss: 0.0153\n",
      "Epoch 61/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0227 - val_loss: 0.0153\n",
      "Epoch 62/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0157 - val_loss: 0.0151\n",
      "Epoch 63/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0237 - val_loss: 0.0150\n",
      "Epoch 64/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0149\n",
      "Epoch 65/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 66/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0214 - val_loss: 0.0147\n",
      "Epoch 67/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0210 - val_loss: 0.0146\n",
      "Epoch 68/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0207 - val_loss: 0.0145\n",
      "Epoch 69/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0233 - val_loss: 0.0144\n",
      "Epoch 70/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0204 - val_loss: 0.0143\n",
      "Epoch 71/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0179 - val_loss: 0.0142\n",
      "Epoch 72/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0222 - val_loss: 0.0142\n",
      "Epoch 73/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0141\n",
      "Epoch 74/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0211 - val_loss: 0.0140\n",
      "Epoch 75/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 76/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0286 - val_loss: 0.0139\n",
      "Epoch 77/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0139\n",
      "Epoch 78/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0192 - val_loss: 0.0140\n",
      "Epoch 79/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0183 - val_loss: 0.0140\n",
      "Epoch 80/100\n",
      "Epoch 00079: early stopping\n",
      "8367/8367 [==============================] - 0s - loss: 0.0237 - val_loss: 0.0140\n"
     ]
    }
   ],
   "source": [
    "model = buildNet(lr = 0.019685168087984706, dropoutA=0.083730742972679156, \n",
    "                 dropoutB=0.37669203808894514,dropoutC=0.26408076037832368)\n",
    "y_pred = trainAndPredict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97354072203409281"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalAUC(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildDeep(lr=.01, dropoutA=.2, dropoutB=.2, dropoutC=.2, dropoutD=.2,dropoutE=.2):\n",
    "    inputLayer = Input(shape = (8,))\n",
    "    D = Dropout(dropoutA)(inputLayer)\n",
    "    D = Dense(64)(D)\n",
    "    D = Activation('relu')(D)\n",
    "    D = Dropout(dropoutB)(D)\n",
    "    D = Dense(32)(D)\n",
    "    D = Activation('relu')(D)\n",
    "    D = Dropout(dropoutC)(D)\n",
    "    D = Dense(16)(D)\n",
    "    D = Activation('relu')(D)\n",
    "    D = Dropout(dropoutD)(D)\n",
    "    D = Dense(8)(D)\n",
    "    D = Activation('relu')(D)\n",
    "    D = Dropout(dropoutE)(D)\n",
    "    pred = Dense(1,activation = 'sigmoid')(D)\n",
    "    model = Model(input = inputLayer, output=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr))\n",
    "    return model\n",
    "\n",
    "def measurableDeep(lr=1e-3, dropoutA=.2, dropoutB=.2, dropoutC=.2, dropoutD=.2, \n",
    "                   dropoutE=.2,nb_epoch=100, batch_size=len(train)):\n",
    "    model = buildDeep(lr,dropoutA,dropoutB,dropoutC,dropoutD,dropoutE)\n",
    "    y_pred = trainAndPredict(model, nb_epoch,batch_size)\n",
    "    return evalAUC(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params1 = {'lr':(1e-3,.1), 'dropoutA':(.01,.6),'dropoutB':(.01,.6),'dropoutC':(.01,.6),\n",
    "            'dropoutD':(.01,.6),'dropoutE':(.01,.6)}\n",
    "BO1 = BayesianOptimization(measurableDeep,params1)\n",
    "BO1.maximize(init_points=5,n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_params': {'dropoutA': 0.30412844220674939,\n",
       "  'dropoutB': 0.38286540709231481,\n",
       "  'dropoutC': 0.19078598982799802,\n",
       "  'dropoutD': 0.21326732936366835,\n",
       "  'dropoutE': 0.092861776007691854,\n",
       "  'lr': 0.074875486052876028},\n",
       " 'max_val': 0.99944517783007136}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BO1.res['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8367 samples, validate on 2789 samples\n",
      "Epoch 1/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.7302 - val_loss: 0.2458\n",
      "Epoch 2/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.2665 - val_loss: 0.1711\n",
      "Epoch 3/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.2085 - val_loss: 0.1583\n",
      "Epoch 4/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.2100 - val_loss: 0.1373\n",
      "Epoch 5/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.1836 - val_loss: 0.1161\n",
      "Epoch 6/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.1642 - val_loss: 0.0956\n",
      "Epoch 7/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.1464 - val_loss: 0.0850\n",
      "Epoch 8/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.1255 - val_loss: 0.0783\n",
      "Epoch 9/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0994 - val_loss: 0.0720\n",
      "Epoch 10/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.1018 - val_loss: 0.0679\n",
      "Epoch 11/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0835 - val_loss: 0.0610\n",
      "Epoch 12/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0846 - val_loss: 0.0521\n",
      "Epoch 13/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0769 - val_loss: 0.0508\n",
      "Epoch 14/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0780 - val_loss: 0.0495\n",
      "Epoch 15/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0761 - val_loss: 0.0503\n",
      "Epoch 16/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0826 - val_loss: 0.0517\n",
      "Epoch 17/100\n",
      "8367/8367 [==============================] - 0s - loss: 0.0779 - val_loss: 0.0520\n",
      "Epoch 18/100\n",
      "Epoch 00017: early stopping\n",
      "8367/8367 [==============================] - 0s - loss: 0.0799 - val_loss: 0.0512\n"
     ]
    }
   ],
   "source": [
    "deep = buildDeep(lr=0.074875486052876028,dropoutA=0.30412844220674939,\n",
    "                 dropoutB=0.38286540709231481,dropoutC=0.19078598982799802,\n",
    "                 dropoutD=0.21326732936366835,dropoutE=0.092861776007691854)\n",
    "y_deep = trainAndPredict(deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94739711875107624"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalAUC(y_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.999169571218\n"
     ]
    }
   ],
   "source": [
    "y_test=test[:,-1]\n",
    "test_pred = model.predict(test[:,:8])\n",
    "test_pred1 = deep.predict(test[:,:8])\n",
    "print evalAUC(test_pred, y_test)\n",
    "print evalAUC(test_pred1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2789, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded = np.round(test_pred)\n",
    "rounded1 = np.round(test_pred1)\n",
    "rounded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 1.0. Specificity: 1.0. Accuracy: 1.0.\n",
      "Deep Sensitivity: 0.0. Deep Specificity: 1.0. Deep Accuracy: 0.988884904984.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(y_pred, y_true):\n",
    "    rounded = np.transpose(np.round(y_pred))\n",
    "    tp = np.sum((rounded==1) & (y_true==1))\n",
    "    fn = np.sum((rounded==0) & (y_true==1))\n",
    "    tn = np.sum((rounded==0) & (y_true==0))\n",
    "    fp = np.sum((rounded==1) & (y_true==0))\n",
    "    sens = float(tp)/(tp+fn)\n",
    "    spec = float(tn)/(tn+fp)\n",
    "    acc = float(tp+tn)/(tp+fn+fp+tn)\n",
    "    return (sens, spec, acc)\n",
    "y_test=test[:,-1]\n",
    "test_sens, test_spec, test_acc = evaluate(test_pred,y_test)\n",
    "test_sens1, test_spec1, test_acc1 = evaluate(test_pred1,y_test)\n",
    "print \"Sensitivity: \"+str(test_sens)+\". Specificity: \"+str(test_spec)+\". Accuracy: \"+str(test_acc)+\".\"\n",
    "print \"Deep Sensitivity: \"+str(test_sens1)+\". Deep Specificity: \"+str(test_spec1)+\". Deep Accuracy: \"+str(test_acc1)+\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.921052631579. Specificity: 0.99963649582. Accuracy: 0.998565794191.\n",
      "Deep Sensitivity: 0.0. Deep Specificity: 1.0. Deep Accuracy: 0.986375044819.\n"
     ]
    }
   ],
   "source": [
    "val_true=val[:,-1]\n",
    "\n",
    "val_sens, val_spec, val_acc = evaluate(y_pred,val_true)\n",
    "val_sens1, val_spec1, val_acc1 = evaluate(y_deep,val[:,-1])\n",
    "print \"Sensitivity: \"+str(val_sens)+\". Specificity: \"+str(val_spec)+\". Accuracy: \"+str(val_acc)+\".\"\n",
    "print \"Deep Sensitivity: \"+str(val_sens1)+\". Deep Specificity: \"+str(val_spec1)+\". Deep Accuracy: \"+str(val_acc1)+\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14113740140506925"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.998565794191/0.986375044819-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"TunedNN.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
